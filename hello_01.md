官网: https://kafka.apache.org/downloads.html

下载  kafka_2.12-2.4.0.tgz

中文参考资料: 
http://kafka.apachecn.org/intro.html
https://www.orchome.com/kafka/index

简明教程
http://bridgeforyou.cn/2018/05/28/Kafka-Tutorial/

问题
====

kafka节点之间如何复制备份的？
kafka消息是否会丢失？为什么？
kafka最合理的配置是什么？
kafka的leader选举机制是什么？
kafka对硬件的配置有什么要求？
kafka的消息保证有几种方式？
kafka为什么会丢消息？

基本概念
=======

Topic
    Kafka将消息分门别类，每一类的消息称之为一个主题（Topic）。

Producer
    发布消息的对象称之为主题生产者（Kafka topic producer）

Consumer
    订阅消息并处理发布的消息的对象称之为主题消费者（consumers）

Broker
    已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理（Broker）。 
    消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。

四个核心的API
==================

The Producer API 
    允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。

The Consumer API 
    允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。

The Streams API 
    允许一个应用程序作为一个流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或
    多个topic中去，在输入输出流中进行有效的转换。

The Connector API 
    允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。
    比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。

主题和日志 （Topic和Log）
========

对于每个topic，Kafka集群都会维护一个分区log
每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配
一个id号来表示顺序，我们称之为offset，offset用来唯一的标识分区中每一条记录。

Kafka 集群保留所有发布的记录—无论他们是否已被消费—并通过一个可配置的参数——保留期限来控制. 举个例子， 
如果保留策略设置为2天，一条记录发布后两天内，可以随时被消费，两天过后这条记录会被抛弃并释放磁盘空间。
Kafka的性能和数据大小无关，所以长时间存储数据没有什么问题.

在每一个消费者中唯一保存的元数据是offset（偏移量）即消费在log中的位置.偏移量由消费者所控制:通常在读取记录后，
消费者会以线性的方式增加偏移量，但是实际上，由于这个位置由消费者控制，所以消费者可以采用任何顺序来消费记录。例
如，一个消费者可以重置到一个旧的偏移量，从而重新处理过去的数据；也可以跳过最近的记录，从"现在"开始消费。

日志中的 partition（分区）有以下几个用途。
    第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，
        不过一个主题可能有多个分区，因此可以处理无限量的数据。
    第二，可以作为并行的单元集

分布式
=====

日志的分区partition （分布）在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。
每一个分区都会在已配置的服务器上进行备份，确保容错性.

每个分区都有一台 server 作为 “leader”，零台或者多台server作为 follwers 。leader server 处理一切对
partition （分区）的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers 中的一
台服务器会自动成为新的 leader。每台 server 都会成为某些分区的 leader 和某些分区的 follower，因此集群的负
载是平衡的。

生产者
=====

生产者可以将数据发布到所选择的topic（主题）中。生产者负责将记录分配到topic的哪一个 partition（分区）中。
可以使用循环的方式来简单地实现负载均衡，也可以根据某些语义分区函数(例如：记录中的key)来完成。

消费者
=====

消费者使用一个 消费组 名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的一个消费者实例.
消费者实例可以分布在多个进程中或者多个机器上。

如果所有的消费者实例在同一消费组中，消息记录会负载平衡到每一个消费者实例.

如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程.


链接：https://www.orchome.com/5

传统的队列模型保持消息，并且保证它们的先后顺序不变。但是， 尽管服务器保证了消息的顺序，消息还是异步的发送给各个
消费者，消费者收到消息的先后顺序不能保证了。这也意味着并行消费将不能保证消息的先后顺序。用过传统的消息系统的同学
肯定清楚，消息的顺序处理很让人头痛。如果只让一个消费者处理消息，又违背了并行处理的初衷。 在这一点上Kafka做的更
好，尽管并没有完全解决上述问题。 Kafka采用了一种分而治之的策略：分区。 因为Topic分区中消息只能由消费者组中的唯
一一个消费者处理，所以消息肯定是按照先后顺序进行处理的。但是它也仅仅是保证Topic的一个分区顺序处理，不能保证跨分
区的消息先后处理顺序。 所以，如果你想要顺序的处理Topic的所有消息，那就只提供一个分区。